Initially from 3 Datasets --> SDC Platinum | Compustat | ?

SDC Platinum	-> merge information
Compustat   	-> Financial information
? 				-> ...

SDC Platinum contains detailed datasets on mergers and acquisitions for the global financial marketplace.
Compustat is a database of financial, statistical and market information on active and inactive global companies throughout the world. 


From these three datasets, finally we had 4822 records containing the aquistion information of companies from 1980-2013. Since we are interested only from 1996-2013 we were left with 1074 records. After Industry Classification(Industry Codes SIC's) of these 1074 companies based on Akbar Zaheer research paper we were left with 993 records. We tought of analysing the past three years patents, considering this 3 years lag the final list contained 816 target companies(816_target_gvkeys.csv).

4822 -> 1980-2013 
1074 -> 1996-2013
993 -> Industry Codes SIC's
816 -> 1999-2013 (3 years lag)

Same process has been done for Acquirer companies and finally we are left with 525 Acquirer companies(Acquirer companies.csv).


How acquitions and merging of comapnies work in product space and knowledge space:

----------------------------------------------------------------------------------------------------------------------------------------
														PRODUCT SPACE 
----------------------------------------------------------------------------------------------------------------------------------------

TNIC Data ->  Universal Data which contains the density between any two companies for all companies for all 	                                        estimated years.

Assuming a company as node which is connected to other nodes(other companies) which are again interlinked in the network.
Now the overall density_index(proximity val) of a particular company has been calculated by taking the ratio of upper triangle in this   2-d matrix(n*n matrix denpting densities between companies) to the overall possible.


														Product Space Codes: 
														-------------------

tnic_all_years_data.csv :
-----------------------
Universal Data which contains the density between any two companies for all companies (each and every acquisition and their estimated year). 

code.py :
---------
(1) Checking for gvkey 2598 and dealyear 1999.
(2) Created uniquelist from tnic data for this particular gvkey(from appending dataframes or extending lists).
(3) For every key in this uniquelist corresponding 3 values(past 3 years) and average value has ben generated,(upper tringle in 2-d matrix) and calculated the density.


code1.py :
----------
(1) For uniquelist generated by extending the list.
(2) Tried to find density for all 816 companies.
(3) Computing -> taking more time(around 30min for each company as the entire data to be searched for every entry in upper triangle of
    2-d matrix.)

    To optimise searching entire data for each and every entry:


code2.py :
----------
(1) Unique list has been created by appending dataframes and removing duplicates.
(2) Now a new dataframe has been generated from this uniquelist which contains data related to all keys in this uniquelist which
	reduced the computing time by greater extent.
(3) Calculated density for gvkey 2598 and year 1999.


code3.py :
----------
(1) Tried to find densities of all 816 companies through the procedure mentioned in code2.py.
(2) Computing still taking more time, as for some companies(gvkeys) uniquelist contained around 500 elements and the dataframe
    generated by this uniquelist is still large and this entire dataframe has to be searched for each and every entry.

MAProject_Code.R :
------------------
(1) Part of the code executed in R.


Still need to work on optimising Product Space Codes.
code3.py still taking morre time(around weeks).Need to optimise it further.


-----------------------------------------------------------------------------------------------------------------------------------------
														KNOWLEDGE SPACE
-----------------------------------------------------------------------------------------------------------------------------------------

We looked at the product space behaviour. Now we are finding how the same varies in the knowledge space. Apart from the product space behaviour there has to be something that drives a deal(acquisition or merging two companies). Assuming that patents filed by a company plays a major role in this process and considering them to be the crucial factor in deciding the deal we are looking at how these patents and their forward and backward citations are linked. Assuming a company looks at the other companies past 3 years data(here we are assuming it to be the patent data, we are considering the patents filed in the past three years prior to the deal) before merging or acquiring other. 


Working on Knowledge Space ...


														Knowledge Space Codes:
														----------------------

															NBER Dataset:
															------------
NBER Dataset was based on 

DYNASS.csv			->	pdpassgn of respective gvkeys.
PAT76_06_assgn.csv  ->	patents of these pdpassgn.

816_target_gvkeys.csv contained 816 target companies with corresponding gvkeys

code1.py :
----------
(1) From DYNASS.csv file extracted corresponding final gvkeys of each rows
(2) Separated rows with negative pdpass(58) and their corresponding final gvkeys into negDYNASS.csv file
(3) Created fnlDYNASS.csv file which contains all pdpass and their corresponding final gvkeys.
(4) This wasn't much useful as we could only generate assignees for 270 companies outof 816


code2.py :
----------
(1) For 816 targetted companies compared their gvkeys with gvkeys in DYNASS.csv gvkey5 --- gvkey1(5 else 4 ... 1) and took the 		    
    corresponding gvkey and mapped to respective pdpass(removing duplicate values) and created 816_target_gvkeys_assgn_525.csv file.
(2) Finally generated assignees for 525 targetted companies out of 816
(3) Some companies had multiple assignees.


code3.py :
----------
(1) For 270 targetted companies out of 816 generated in code1.py from final gvkeys mapped to their corresponding assignees and     
    created 816_target_gvkeys_assgn_270.csv file


code4.py :
----------
(1) For 525 targetted companies out of 816 generated in code2.py corresponding patents from PAT76_06_assg.csv have been generated, 
    created 816_assgn_patent.csv file(each company -> multiple assignees and each each assignee -> multiple patents) and their patent counts.


code5.py :
----------
(1) From 816_target_gvkeys_assgn_525.csv generated in code2.py the data has been expanded vertically with each pdpasignee in each row.
(2) By Finding the assignee count for each row and expanding each row with its respective assignee count and finally replacing pdpassgn 
    column (list of lists) with a single list, generated the file 816_target_gvkeys_assgn__expand_525.csv .


code6.py :
----------
(1) Now taking the 816_target_gvkeys_assgn__expand_525.csv generated in code5.py for each pdpassgn respective list of patents have been 
    generated as in code4.py and created file 816_assign_patent_expand.csv .


code7.py :
----------
(1) Now for the 816_assign_patent_expand.csv file generated in code6.py above, generated the 816_assign_patent_expand_final.csv file 
    which contains company with single pdpassgn and single patent in each row as done in code5.py for genrating assignees in each row.
(2) Finally, we have the list of all 816 companies with all possible assignees and respective patents expanded vertically.(which could 
    be used to get citations for each patent in next step.)



															NBER Acquirer:
															-------------

Similarly for 525 Acquirer companies based on their gvkeys corresponding pdpassgn and their patents are found as done for 816 target companies.

Acquirercomanies.csv:
	Contains list of 525 Acquirer companies with their gvkeys and deal years.

code8.py :

(1) Similar to code2.py Acquirer_Assignees.csv has been created, corresponding assignees have been created for all gvkeys.

code9.py :

(1) Assignees have been expanded vertically as done in code5.py, created Acquirer_Assignees_Expand.csv.

code10.py :

(1) From the above file corresponding patents and their counts have been extracted as done in code6.py.
(2) Created the file Acquirer_Assignees_Patent_Expand.csv.

code11.py :

(1) Now from the above generated file patents have been expanded vertically similar to code7.py.
(2) Finally, Acquirer_Assignees_Patent_Expand_Final.csv has been generated which contains list of all Acquirer companies with respective 
    assignees and patents.





-----------------------------------------------------------------------------------------------------------------------------------------
														HARVARD DATAVERSE				
-----------------------------------------------------------------------------------------------------------------------------------------

Disambiguities have been removed from USPTO

From NBER Dataset we extracted the patents file by these 816 target comapnies and 525 acquirer companies. Now we need to find the citations of these patents. For finding citations we are moving to Harvard Dataverse since they are more reliable.

Harvard Dataverse contains:
Assignee
Citation75_99
Citation00_10
Patent and 
Invpat

Due to large file size, these files couldn't be processed using python. Sql queries(Sqlite Browser) have been written to extract the required data.

Working on target companies:

-----------------------------------------------------------------------------------------------------------------------------------------
														First Step:
-----------------------------------------------------------------------------------------------------------------------------------------

-> invpat contained information related to patents.
-> From 816_patents file generated through NBER missing values have been handled(records with missing values have been removed)
   and 0 has been appended to the patent column as harvard data contained leading 0 for every patent and created patent816 file.


Joining patent816 file and invpat file based on patents and applying dealyear filter:
-----------------------------------------------------------------------------------------------------------------------------------------

(1)  SELECT * FROM invpat JOIN patent816 ON (patent816.Patent1=invpat.Patent) where  patent816.dealyear-invpat.AppYearStr<=3 AND 
     patent816.dealyear-invpat.AppYearStr>=1

	(a) SELECT * FROM invpat JOIN patent816 ON (patent816.Patent1=invpat.Patent)
	    71043 records returned after joining invpat with patent816.

	(b) SELECT * FROM a_invpat_patfile_join where dealyear-AppYearStr<=3 AND dealyear-AppYearStr>=1
	    7385 records returned after applying the deal year filter.

Created a_invpat_patfile_join.csv removed duplicate patent column.


Joining a_invpat_patfile_join file and citation files based on patents:
-----------------------------------------------------------------------------------------------------------------------------------------

(1) open invpat database and attach citation75_99 and citation00_10 databases and run the following query to get corresponding citations 
    of these patents.

	(a) Select * from citation75_99 join a_invpat_patfile_join on a_invpat_patfile_join.Patappend=citation75_99.Patent
	    union
	    Select * from  citation00_10 join a_invpat_patfile_join on a_invpat_patfile_join.Patappend=citation00_10.Patent 

	(b) 196900 records returned after joining these two files.
	(c) Created invpat_patfile_citfiles_join file.(This file contains patent gvkey invpat and their citation details.)


After first step target companies->patents->citations.

-----------------------------------------------------------------------------------------------------------------------------------------
														Second Step:
-----------------------------------------------------------------------------------------------------------------------------------------

Now we have the list of all patents filed and their citations list of all 816 companies. Now, we need to file the companies to which these citations belong and their patents and citations.


Finding Company details of these citations:
-----------------------------------------------------------------------------------------------------------------------------------------
To find which companies these citations belong, Join the above generated file with invpat as citations are also patents filed by some companies
	
	cit816assgnpatents 6.34gb file generated when all citations of the above file with their AsgNum(obtained after joining with invpat based on citation and patent) are joined with invpat again 
	based on AsgNum to get all patents(without applying dealyear filter) filed by these assignees. Since this data can't be handled process only required columns ...

(1) Citations->Assigneees
	
	(a) cit816harvard.csv has been generated by chosing only required columns from invpat_patfile_citfiles_join.csv
        select gvkey,dealyear,Patent,Citation from invpat_patfile_citfiles_join

        change Patent    -> FocalPatent
  	           Citation  -> Citations_FP
  	    append 0 and join with invpat to get details of these citations

	(b) cit816harvard1.csv has been generated by joining two files
	    ->	select gvkey,dealyear,FocalPatent,Citations_FP,Assignee,AsgNum,Class from invpat join cit816harvard on cit816harvard.
	        Citations_FPapp=invpat.Patent
	    ->	97716 records are returned from this join.	


	(c)	cit816harvard1remdup.csv has been generated by selecting only distinct rows from the join which reduced the output size.
		->	select distinct gvkey,dealyear,FocalPatent,Citations_FP,Assignee,AsgNum,Class from invpat join cit816harvard on    
			cit816harvard.Citations_FPapp=invpat.Patent
		->  Only 14153 records are returned.


	(d) Some of these rows contained missing values they have been removed(python) and cit816harv.csv has been generated.
  		->	cit816harv.csv contained only 12221 records which need to be handled.


(2)	Citations->Assignees->Patents->Citations (Not Succesful)
	
	NOw, As the asgnum have been made unique joining with invpat based on asgnum will give the patents filed by these assignees.

	(a)	To get citation assignees patents
  		select * from cit816harv join invpat on (invpat.AsgNum=cit816harv.AsgNum) where cit816harv.dealyear-invpat.AppYearStr<=3 and cit816harv.dealyear-invpat.AppYearStr>=1
  	(b) This query couldnt be processed since it has to handle much data. So, to reduce the data to be handled:



(3)	
	
	Instead of considering all citations from invpat_patfile_citfiles_join consider only distinct citations.
	(a) select distinct Citation from invpat_patfile_citfiles_join -> citation.csv    
   		-> 29692 unique citations after first step(816patents to citations).
   		-> append 0 and join with invpat patent to get patents list.
   		-> Now we have the list of unique citations and the companies to which they belong. We need to find patents of all these 
   		   Assignees and their citations.
   		
   	(b) select distinct Citation,Assignee,AsgNum,Class from citation join invpat on citation.citapp=invpat.Patent
   		-> citationdetail.csv
   		-> 8265 rows returned.
   		-> This file contains details of all the possible Citations and their Assignee Companies.

(4)	
	Citations -> Assignees

	(a)	From cit816harv.csv select only required Unique Assignee number and dealyear(for applying 3yr filter).
		-> select distinct AsgNum,dealyear from cit816harv
	  	-> cit816harv_uniqueasg.csv has been created which contained 2982 rows.

	Assignees -> Patents
	
	(b) Join this with invpat to get patents of these citations
		-> select * from cit816harv_uniqueasg join invpat on cit816harv_uniqueasg.AsgNum=invpat.AsgNum
		-> cit816harv_uniqueasg_invpat.csv has been created which contained around 9744221 rows.
		-> citations of 816 companies -> unique assignees join with invpat. 
		-> We don't need to process all these columns further ...


	(c) So, Instead of taking all columns from the join extract only required columns.
		-> select AsgNum_cit,Assignee,Patent from cit816harv_uniqueasg join invpat on cit816harv_uniqueasg.AsgNum_cit=invpat.AsgNum 
		   where cit816harv_uniqueasg.dealyear-invpat.AppYearStr<=3 and cit816harv_uniqueasg.dealyear-invpat.AppYearStr>=1
		-> cit816harv_uniqueasg_patents.csv has been created which contained 1381574 rows.


	Patents -> Citations 

	(d) Join above file with citation files based on patent to get corresponding citations.
		-> Select * from cit816harv_uniqueasg_patents join citation75_99 on cit816harv_uniqueasg_patents.Patent=citation75_99.Patent
		   union
		   Select * from cit816harv_uniqueasg_patents join citation00_10 on cit816harv_uniqueasg_patents.Patent=citation00_10.Patent 
		-> cit816harv_uniqueasg_patents_citations.csv has been created 3364372 rows.

	Citations -> Citation Assignees and Assignee Numbers
		
	(e) Join above file with invpat to get assignee names and numbers for all citations.
		-> cit816harv_uniqueasg_patents_citations.csv : AsgNum->AsgNum_cit, Assignee->Assignee_cit,Patent->Patents_cit.
		-> Append 0 to citations-> Citation_app
		-> Select AsgNum_cit,Assignee_cit,Patents_cit,Cit_Date,Cit_Name,Citation_app,Assignee,AsgNum from 
		   cit816harv_uniqueasg_patents_citations join invpat on cit816harv_uniqueasg_patents_citations.Citation_app=invpat.Patent 
		-> cit816harv_uniqueasg_patents_citations1.csv is created with 2142 rows.
 


Finally,

First step:
	816 Target Companies -> Patents -> Citations.
		(1)invpat_patfile_citfiles_join file 

Second Step:
	Citations -> Assignees
		(1)cit816harv.csv
	Unique Assignees -> Patents
		(2)cit816harv_uniqueasg_patents.csv
	Unique Assignee Patents -> Citations
		(3)cit816harv_uniqueasg_patents_citations.csv
		
		
		
		
	-------------------------------------------------------------------------------------------------------------------------------
	To extract required final four files:
	
	(a)	select gvkey,Targetname,dealyear,AppYearStr,Patent,Class,Citation from invpat_patfile_citfiles_join
		->target_cit_temp.csv with 196900 rows
	
	(b)	select gvkey,targetname,dealyear,target_cit_temp.AppYearStr,target_cit_temp.Patent,Citation_app,Assignee,AsgNum from target_cit_temp join invpat on target_cit_temp.Citation_app=invpat.Patent->target_cit_assignee_temp
		->target_cit_assignee_temp.csv with 97716 rows (blanks 7953)
	
	(c)	select distinct gvkey,targetname,dealyear,target_cit_temp.AppYearStr,target_cit_temp.Patent,Citation_app,Assignee,AsgNum from target_cit_temp join invpat on target_cit_temp.Citation_app=invpat.Patent->target_cit_assignee_temp
		->target_cit_assignee_temp_distinct.csv with 14153 rows and after removing duplicates(python) 
		->target_cit_assignee_temp_distinct_null with 12221 rows renamed and created final file1
		->file1 : target_pat_cit_assignee
	
	(d)	select distinct AsgNum,dealyear from target_cit_assignee_temp_distinct_null
		->unique_Assignee_number.csv with 2982 rows
		
	(e)	select distinct gvkey,Targetname,dealyear,Patent,Class from target_cit_temp
		->file3: target_pat_class
		
	(f)	select AsgNum_cit,Assignee,Patent from cit816harv_uniqueasg join invpat on cit816harv_uniqueasg.AsgNum_cit=invpat.AsgNum 
		   where cit816harv_uniqueasg.dealyear-invpat.AppYearStr<=3 and cit816harv_uniqueasg.dealyear-invpat.AppYearStr>=1
		->file4.csv with 1381574 rows
		
	(g)	select AsgNum_cit,Assignee,Patent,dealyear,AppYearStr from cit816harv_uniqueasg join invpat on cit816harv_uniqueasg.AsgNum_cit=invpat.AsgNum 
		   where cit816harv_uniqueasg.dealyear-invpat.AppYearStr<=3 and cit816harv_uniqueasg.dealyear-invpat.AppYearStr>=1
		->cit816harv_uniqueasg_patents.csv with 1381574
		->Modified previous cit816harv_uniqueasg_patents by adding dealyear and AppYearStr
		
	(h)	Select * from cit816harv_uniqueasg_patents join citation75_99 on cit816harv_uniqueasg_patents.Patent=citation75_99.Patent
		union
		Select * from cit816harv_uniqueasg_patents join citation00_10 on cit816harv_uniqueasg_patents.Patent=citation00_10.Patent
		->cit816harv_uniqueasg_patents_citations_file2temp.csv created with 5270337 records.
		->Selected required columns from this file and created cit816harv_uniqueasg_patents_citations_file2.csv
		
	(i)	select asgnum_cit,cit816harv_uniqueasg_patents_citations_file2.assignee,cit816harv_uniqueasg_patents_citations_file2.patent,dealyear,cit816harv_uniqueasg_patents_citations_file2.appyearstr,citation,invpat.Assignee,invpat.AsgNum from cit816harv_uniqueasg_patents_citations_file2 join invpat on cit816harv_uniqueasg_patents_citations_file2.citation=invpat.patent
		->unqasg_pat_cit_asg_temp.csv created with 12629189 records.
		select distinct asgnum_cit,cit816harv_uniqueasg_patents_citations_file2.assignee,cit816harv_uniqueasg_patents_citations_file2.patent,dealyear,cit816harv_uniqueasg_patents_citations_file2.appyearstr,citation,invpat.Assignee,invpat.AsgNum from cit816harv_uniqueasg_patents_citations_file2 join invpat on cit816harv_uniqueasg_patents_citations_file2.citation=invpat.patent
		-> Created unqasg_pat_cit_asg_distinctfile2. Distinct records are 5071238
		
Need to modify all the above files:
Some of the Citation names are of type A;B when they are exported to csv earlier they got separated into different columns. Previously as we joined citation tables with file some of the citations got different values due to column shift.
So modify all previous files accordingly:
	Select * from a_invpat_patfile_join join citation75_99 on a_invpat_patfile_join.Patappend=citation75_99.Patent 
	union
	Select * from a_invpat_patfile_join join citation00_10 on a_invpat_patfile_join.Patappend=citation00_10.Patent
	invpat_patfile_citfiles_join1 with 196900 records.
	
	
	(a)	select gvkey,Targetname,dealyear,AppYearStr,a_invpat_patfile_join.Patent,Class,Citation from a_invpat_patfile_join join citation75_99 on a_invpat_patfile_join.Patappend=citation75_99.Patent 
		union
		select gvkey,Targetname,dealyear,AppYearStr,a_invpat_patfile_join.Patent,Class,Citation from a_invpat_patfile_join join citation00_10 on a_invpat_patfile_join.Patappend=citation00_10.Patent
		->target_cit_temp1 with 58519 records.
	
	(b)	target_cit_assignee_temp with 132853 records
	(c)	->target_cit_assignee_temp_distinct with 53743 records and after removing nulls(python) target_cit_assignee_temp_distinct_null same as
		->file1 : target_pat_cit_assignee with 46341 records
	(d)	unique_Assignee_number with 9590 records.
	(e)	file3: target_pat_class with 2417 records.
	(f)	Modified cit816harvard: 196900, after removing null values(python): 196459, 
			 cit816harvard1: 460031
			 cit816harvard1remdup: 53636
			 cit816harv: 46239
			 cit816harv_uniqueasg: 9576
			file4: 4451836
	(g)	cit816harv_uniqueasg_patents with 4451836 records.
	(h)	Select AsgNum_cit,Assignee,cit816harv_uniqueasg_patents.Patent,dealyear,AppYearStr,Citation from cit816harv_uniqueasg_patents join citation75_99 on cit816harv_uniqueasg_patents.Patent=citation75_99.Patent
		union
		Select AsgNum_cit,Assignee,cit816harv_uniqueasg_patents.Patent,dealyear,AppYearStr,Citation from cit816harv_uniqueasg_patents join citation00_10 on cit816harv_uniqueasg_patents.Patent=citation00_10.Patent
		->cit816harv_uniqueasg_patents_citations_file2 with 22874946 records. Old file renamed as cit816harv_uniqueasg_patents_citations_file2_old_b4change incase of further use.
	(i)	select cit816harv_uniqueasg_patents_citations_file2.field1,cit816harv_uniqueasg_patents_citations_file2.field2,cit816harv_uniqueasg_patents_citations_file2.field3,cit816harv_uniqueasg_patents_citations_file2.field4,cit816harv_uniqueasg_patents_citations_file2.field5,cit816harv_uniqueasg_patents_citations_file2.field6,invpat.Assignee,invpat.AsgNum from cit816harv_uniqueasg_patents_citations_file2 join invpat on cit816harv_uniqueasg_patents_citations_file2.field6=invpat.Patent
		->unqasg_pat_cit_asg_temp created with 43503194 records.
		select distinct cit816harv_uniqueasg_patents_citations_file2.field1,cit816harv_uniqueasg_patents_citations_file2.field2,cit816harv_uniqueasg_patents_citations_file2.field3,cit816harv_uniqueasg_patents_citations_file2.field4,cit816harv_uniqueasg_patents_citations_file2.field5,cit816harv_uniqueasg_patents_citations_file2.field6,invpat.Assignee,invpat.AsgNum from cit816harv_uniqueasg_patents_citations_file2 join invpat on cit816harv_uniqueasg_patents_citations_file2.field6=invpat.Patent
		->unqasg_pat_cit_asg_distinctfile2.csv replaced with 17092251 records finally.
	
