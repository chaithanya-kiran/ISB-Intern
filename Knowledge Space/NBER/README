3 Datasets --> SDC | Compustat | ?

SDC -> merge information
Compustat -> Financial information
? -> ...


4822 -> 1980-2013 
1074 -> 1996-2013
993 -> Industry Codes SIC's
816 -> 1999-2013 (3 years lag)


Product Space :
---------------
TNIC -> Universal Data which contains the density between any two companies for all companies.
Assuming a company as node which is connected to other nodes(other companies) which are again interlinked in the network.
Now the overall density_index(proximity val) of a particular company has been calculated by taking the ratio of upper triangle in this    2-d matrix(n*n matrix denpting densities between companies) to the overall possible.


Now we are finding how the same varies in the knowledge space assuming a company looks at the other companies past 3 years data(here we are assuming it to be the patent data, how they are related) before merging or acquiring other 


Working on Knowledge Space ...


Knowledge Space :
-----------------

NBER DATA :
---------

816_target_gvkeys.csv contained 816 target companies with corresponding gvkeys

code1.py :

(1) From DYNASS.csv file extracted corresponding final gvkeys of each rows
(2) Separated rows with negative pdpass(58) and their corresponding final gvkeys into negDYNASS.csv file
(3) Created fnlDYNASS.csv file which contains all pdpass and their corresponding final gvkeys.
(4) This wasn't much useful as we could only generate assignees for 270 companies outof 816

code2.py :

(1) For 816 targetted companies compared their gvkeys with gvkeys in DYNASS.csv gvkey5 --- gvkey1(5 else 4 ... 1) and took the 		      corresponding gvkey and mapped to respective pdpass(removing duplicate values) and created 816_target_gvkeys_assgn_525.csv file.
(2) Finally generated assignees for 525 targetted companies out of 816
(3) Some companies had multiple assignees.

code3.py :

(1) For 270 targetted companies out of 816 generated in code1.py from final gvkeys mapped to their corresponding assignees and     created 816_target_gvkeys_assgn_270.csv file

code4.py :

(1) For 525 targetted companies out of 816 generated in code2.py corresponding patents from PAT76_06_assg.csv have been generated, created 816_assgn_patent.csv file(each company -> multiple assignees and each each assignee -> multiple patents) and their patent counts.

code5.py :

(1) From 816_target_gvkeys_assgn_525.csv generated in code2.py the data has been expanded vertically with each pdpasignee in each row.
(2) By Finding the assignee count for each row and expanding each row with its respective assignee count and finally replacing pdpassgn column (list of lists) with a single list, generated the file 816_target_gvkeys_assgn__expand_525.csv .

code6.py :

(1) Now taking the 816_target_gvkeys_assgn__expand_525.csv generated in code5.py for each pdpassgn respective list of patents have been generated as in code4.py and created file 816_assign_patent_expand.csv .

code7.py :

(1) Now for the 816_assign_patent_expand.csv file generated in code6.py above, generated the 816_assign_patent_expand_final.csv file which contains company with single pdpassgn and single patent in each row as done in code5.py for genrating assignees in each row.
(2) Finally, we have the list of all 816 companies with all possible assignees and respective patents expanded vertically.(which could be used to get citations for each patent in next step.)
